---
title: The New Maker Schedule Isn't About Making
date: 2025-10-08
excerpt: AI agents are turning makers into directors. Our leverage now comes from orchestrating systems, not executing tasks.
description: How AI agents are turning makers into directors
tags: [update]
cover: /images/director-schedule.png
thumbnail: /images/director-schedule-thumbnail.png
author: Chase Adams
category: Context Window
---

**Paul Graham's taxonomy is dead.**

In 2009, Paul Graham divided knowledge workers into two categories: 
- **Makers**: who need long blocks of uninterrupted time
- **Managers**: who live in hourly fragments coordinating others 
 
This binary has organized fifteen years of productivity discourse, spawned countless blog posts about deep work, and justified a million declined meeting requests.

Every creative professional learned to guard their maker time like a temple. Every executive accepted their calendar's transformation into confetti.

The taxonomy made sense because it mapped to a fundamental constraint: human cognitive bandwidth.

A programmer could write code or attend meetings, but not both simultaneously. A designer could create or coordinate, never in parallel. The boundary between making and managing was carved by the serial nature of human attention.

That constraint just dissolved.

## The Collapse of Sequential Work

Consider the mathematics of traditional knowledge work:

The algebra of individual productivity has always been simple: multiply your focused hours by your skill level and the leverage your tools provide.

<div class="my-8 flex justify-center">
  <span class="inline-flex items-center rounded-2xl border border-foreground/15 bg-background-alt/40 px-6 py-4 text-center font-mono text-base font-bold uppercase tracking-[0.08em] text-foreground">
   Maker Output = (Focus Hours) × (Skill Level) × (Tool Leverage)
  </span>
</div>

The manager's equation runs on different physics. Impact flows from the quality and quantity of decisions, amplified through the people who execute them.

<div class="mb-8 flex justify-center">
  <span class="inline-flex items-center rounded-2xl border border-foreground/15 bg-background-alt/40 px-6 py-4 text-center font-mono text-base font-bold uppercase tracking-[0.08em] text-foreground">
Manager Output = (Decisions × Quality × Team Size)
  </span>
</div>

These equations assumed mutual exclusivity. Increase focus hours, decrease coordination points. The trade-off was law. It was encoded in our calendars, our job titles, our very identity. 

You were a maker or a manager, rarely both, never simultaneously.

But what happens when an AI agent can maintain multiple parallel threads of execution while you sleep? 

When it can write code in one context window, analyze markets in another, draft presentations in a third, all while maintaining perfect recall of your strategic intent?

The mutual exclusivity collapses. The equation breaks.

**We're not getting better tools. We're getting parallel selves.**

## The Mechanics of Dissolution

The shift from GPT-3 to GPT-4 wasn't about quality, it was about context. From 4,000 tokens to 128,000 tokens. From holding a conversation to holding an entire codebase in memory. Most dismissed this as a technical detail. They missed the phase transition.

At 4,000 tokens, AI was a sophisticated autocomplete.
At 128,000 tokens, it became an extension of working memory.
At 1 million tokens (already possible), it becomes an external lobe.

The processing speed tells another story. A senior developer might refactor 100 lines of code in an hour. An AI agent processes the same refactoring in twelve seconds. Not 2x faster. Not 10x faster. 300x faster. At that speed differential, iteration approaches instantaneous. The feedback loop collapses to zero.

**Iteration Time (Human): 60 minutes**
**Iteration Time (AI): 12 seconds**
**Speed Multiple: 300x**

This isn't automation. Automation replaces repetitive tasks. This replaces the iterative loop itself.

## The Emergence of Directors

When execution becomes instantaneous and parallel, a new role emerges. Not maker, not manager, but director—someone who orchestrates outcomes across multiple AI agents without touching the work directly.

The director doesn't write code; they define what the codebase should accomplish. They don't design interfaces; they establish the principles that generate them. They don't manage tasks; they architect systems that manage themselves.

This isn't delegation. Delegation implies transfer of responsibility. Direction implies multiplication of capability.

A maker works with materials.
A manager works through people.
A director works through systems.

The director's schedule has no blocks. No maker time, no manager time. Instead, it consists of what I call "state changes"—moments where you alter the trajectory of multiple parallel processes with a single decision.

## The New Productivity Physics

Traditional productivity followed Amdahl's Law: the speedup of a system is limited by its sequential components. If 90% of your work could be parallelized but 10% remained sequential, your maximum speedup was 10x, regardless of resources thrown at it.

Directors operate under different physics—more like Gustafson's Law: as parallel processing power increases, the problem space expands to utilize it. Instead of doing the same work faster, you do categorically more work.

A maker might perfect a single design.
A director spawns a hundred variations, tests them against each other, and synthesizes the best elements into something unprecedented.

The constraint shifts from execution to imagination.

## Historical Parallels and Breaks

The last time we saw this kind of role transition was the shift from craftsman to factory owner during industrialization. But that analogy breaks down immediately. Factory owners needed capital, land, machinery, workers. Directors need a laptop and $20/month for API access.

The Renaissance workshop might be closer—Leonardo directing assistants to execute multiple commissioned works simultaneously while he provided the vision and crucial details. But Leonardo's assistants were human, with human limitations. AI agents don't tire, don't misinterpret, don't need motivation.

We're not recreating historical models. We're in unprecedented territory.

## The Violence of the Transition

Here's what dies: the satisfaction of craft.

For ten thousand years, humans have found meaning in the direct manipulation of materials. The potter at the wheel. The programmer in the zone. The writer finding the perfect word. That feedback loop between hand and material, between thought and expression—it shaped us.

The director's schedule offers power without touch. Impact without contact. Creation without craft.

You can direct the generation of a thousand images but never feel the resistance of paint against canvas. You can orchestrate the writing of a million words but never experience the satisfaction of finding the perfect sentence yourself. You can spawn entire applications but never know the particular pleasure of debugging a subtle error at 3 AM.

The math is irrefutable:

**Director Output = (Vision Clarity) × (AI Agents) × (Parallel Processes)**

When AI Agents approaches dozens and Parallel Processes approaches hundreds, Director Output dwarfs anything possible through direct making or traditional managing. The math wins. The craft loses.

## The Uncomfortable Questions

What happens to human development when we skip the making phase entirely? Can you direct what you've never done?

The traditional path was apprentice to journeyman to master. Each stage built intuition through repetition, wisdom through error. Directors may never touch the materials they direct. They may orchestrate symphonies without knowing how to play an instrument.

Is that wisdom or ignorance at scale?

When everyone can be a director, who provides direction worth following? If execution is free, does vision become priceless or worthless?

## The New Constraints

The bottleneck shifts from execution to judgment. From bandwidth to taste. From capability to discernment.

In a world where you can create anything instantly, the question becomes: what should exist? When you can test a thousand variations, how do you recognize the right one? When every idea can be realized, which ideas deserve realization?

These aren't productivity questions. They're philosophical questions. But they're about to become urgently practical.

## The Choice Architecture

The maker's schedule asked: How should I spend my focused hours?
The manager's schedule asked: How should I coordinate others?
The director's schedule asks: What world should I will into being?

It's not a bigger question. It's a different category of question.

You're no longer choosing between tasks. You're choosing between futures. Each prompt to an AI agent, each system you orchestrate, each process you spawn—they're votes for a particular version of reality.

The director's schedule isn't about time management. It's about outcome selection from an infinite possibility space.

## The Immediate Implications

Right now, someone is treating AI like a better search engine. Someone else is orchestrating seventeen agents to reimagine their industry. The gap between these two approaches isn't technological—it's conceptual.

The tools exist. Claude can maintain context over a small book's worth of information. GPT-4 can code, analyze, write, and reason in parallel. Open-source models can run on your laptop, infinitely customized to your needs. The infrastructure is ready.

What's missing is the mental model.

We're still thinking like makers and managers in a world that rewards directors. We're optimizing our calendars when we should be orchestrating systems. We're protecting our focus time when we should be multiplying our presence.

## The End of Graham's Binary

The maker/manager schedule assumed scarcity—scarce attention, scarce time, scarce cognitive resources. The director's schedule assumes abundance—infinite parallel processing, instantaneous iteration, unlimited experimental capacity.

These aren't compatible worldviews. They're different universes.

In Graham's universe, you chose your species. Maker or Manager. Then you optimized accordingly.

In the director's universe, you transcend the binary entirely. You don't choose between making and managing. You orchestrate systems that do both, simultaneously, continuously, without your direct involvement.

The question isn't whether you're a maker or a manager anymore.

The question is: **are you still operating under constraints that no longer exist?
**